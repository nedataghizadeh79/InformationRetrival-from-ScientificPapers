{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "!pip install zipfile\n",
        "!pip install os\n",
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSC0O_3EhW--",
        "outputId": "336c2d15-0fca-4eca-d5fb-ad63cfccd871"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement zipfile (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for zipfile\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement os (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for os\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting openai\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import zipfile\n",
        "import os\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "import time\n",
        "import pickle\n",
        "from google.colab import drive\n",
        "import openai\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def pdf_to_text(pdf_path):\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "        pdf_reader = PdfReader(file)\n",
        "        text = ''\n",
        "        for page_num in range(len(pdf_reader.pages)):\n",
        "            page = pdf_reader.pages[page_num]\n",
        "            text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "def extract_experiment_section(text):\n",
        "    start_keyword = \"INTRODUCTION\"\n",
        "    end_keyword = \"DISCUSSION\"\n",
        "    start_index = text.find(start_keyword)\n",
        "    end_index = text.find(end_keyword)\n",
        "\n",
        "    if start_index != -1 and end_index != -1:\n",
        "        return text[start_index:end_index]\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "openai.api_key = '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'\n",
        "\n",
        "prompt = \"\"\"\n",
        "Prompt: Experimental Design and Recruitment\n",
        "\n",
        "Please write a detailed description of your experiment's design, recruitment process, and essential parameters. Include the following information.\n",
        "Please provide only the numerical or name-based information for each of the following aspects of your experiment's design and recruitment process:\n",
        "\n",
        "Number of Participants and Recruitment Method:\n",
        "Describe the total number of participants involved in the experiment.\n",
        "Explain how these participants were recruited. Mention any specific criteria used for participant selection (e.g., age, gender, expertise, etc.).\n",
        "\n",
        "Number of Tasks:\n",
        "Specify the total number of tasks or activities presented to the participants during the experiment.\n",
        "\n",
        "Type of Experiment:\n",
        "Indicate the type of experiment conducted. It could be a user study, interview-based study, controlled lab experiment, online survey, etc. Please provide a brief explanation of why this experimental approach was chosen.\n",
        "\n",
        "Experimental Variables:\n",
        "Identify and describe the experimental variables used in the study. This includes both independent variables (factors) and their respective levels.\n",
        "If applicable, clarify any control variables considered to minimize confounding effects.\n",
        "\n",
        "Number of Trials:\n",
        "State the total number of trials or repetitions for each task, if applicable.\n",
        "\"\"\"\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/Colab Notebooks/three-for-test-CHI.zip'\n",
        "unzip_dir = '/content/drive/MyDrive/Colab Notebooks/three-for-test-CHI/'\n",
        "\n",
        "output_df = pd.DataFrame(columns=['PDF Name', 'Output'])\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(unzip_dir)\n",
        "\n",
        "for filename in os.listdir(unzip_dir):\n",
        "    if filename.endswith('.pdf'):\n",
        "        pdf_path = os.path.join(unzip_dir, filename)\n",
        "        text_content = pdf_to_text(pdf_path)\n",
        "        experiment_section = extract_experiment_section(text_content)\n",
        "\n",
        "        if experiment_section is not None:\n",
        "            combined_prompt = prompt + \"\\n\\n\" + \"Extracted Text:\" + \"\\n\" + experiment_section\n",
        "            combined_prompt = combined_prompt[:4097]  # ensure the combined prompt doesn't exceed the model's token limit\n",
        "\n",
        "            response = openai.Completion.create(\n",
        "              engine=\"text-davinci-003\",\n",
        "              prompt=combined_prompt,\n",
        "              max_tokens=500  # you may need to adjust this value as well to stay within the total token limit\n",
        "            )\n",
        "\n",
        "            output_df = output_df.append({'PDF Name': filename, 'Output': response.choices[0].text.strip()}, ignore_index=True)\n",
        "        else:\n",
        "            output_df = output_df.append({'PDF Name': filename, 'Output': \"No Experiment section found in the text.\"}, ignore_index=True)\n",
        "\n",
        "output_df.to_excel('/content/drive/MyDrive/Colab Notebooks/OutputTest.xlsx', index=False)  # Final save.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RERg-zPqive",
        "outputId": "bf3f8b76-e65d-41b8-bbe8-bbb28b8516da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "!pip install bs4\n",
        "!pip install zipfile\n",
        "!pip install os\n",
        "!pip install openai\n",
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXsylwfc62Sd",
        "outputId": "3ec2f977-5b93-4ef0-f99e-8ff896cfbe12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.22.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.10/dist-packages (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4) (2.4.1)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement zipfile (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for zipfile\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement os (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for os\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.8)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import zipfile\n",
        "import os\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "import time\n",
        "import pickle\n",
        "from google.colab import drive\n",
        "import openai\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "output_save_interval = 2  # Save output after every 2 files.\n",
        "processed_files_count = 0\n",
        "\n",
        "def html_to_text(html_path):\n",
        "    with open(html_path, 'r', encoding='utf-8') as file:\n",
        "        soup = BeautifulSoup(file, 'html.parser')\n",
        "        text = soup.get_text()\n",
        "    return text\n",
        "\n",
        "def read_pdf(pdf_path):\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "        pdf_reader = PyPDF2.PdfFileReader(file)\n",
        "        text = \"\"\n",
        "        for page_num in range(pdf_reader.numPages):\n",
        "            page = pdf_reader.getPage(page_num)\n",
        "            text += page.extractText()\n",
        "    return text\n",
        "\n",
        "def extract_experiment_section(text):\n",
        "    start_keyword = \"INTRODUCTION\"\n",
        "    end_keyword = \"DISCUSSION\"\n",
        "    start_index = text.find(start_keyword)\n",
        "    end_index = text.find(end_keyword)\n",
        "\n",
        "    if start_index != -1 and end_index != -1:\n",
        "        return text[start_index:end_index]\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def load_processed_files_list():\n",
        "    try:\n",
        "        with open('processed_files_list.pkl', 'rb') as f:\n",
        "            return pickle.load(f)\n",
        "    except FileNotFoundError:\n",
        "        return []\n",
        "\n",
        "def save_processed_files_list(processed_files):\n",
        "    with open('processed_files_list.pkl', 'wb') as f:\n",
        "        pickle.dump(processed_files, f)\n",
        "\n",
        "api_keys = ['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', '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', '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']\n",
        "api_key_index = 0\n",
        "openai.api_key = api_keys[api_key_index]\n",
        "\n",
        "prompt = \"\"\"\n",
        "Please provide only the information about Number of Participants and Recruitment Method, Number of Tasks, Type of Experiment, Experimental Variables and Number of Trials for each of the following aspects of experiment's design and recruitment process:\n",
        "\n",
        "Number of Participants and Recruitment Method:\n",
        "The total number of participants involved in the experiment.\n",
        "How these participants were recruited. Also any specific criteria used for participant selection (e.g., age, gender, expertise, etc.).\n",
        "\n",
        "Number of Tasks:\n",
        "The total number of tasks or activities presented to the participants during the experiment.\n",
        "\n",
        "Type of Experiment:\n",
        "The type of experiment conducted. It could be a user study, interview-based study, controlled lab experiment, online survey, etc.\n",
        "\n",
        "Experimental Variables:\n",
        "The experimental variables used in the study. This includes both independent variables (factors) and their respective levels.\n",
        "\n",
        "Number of Trials:\n",
        "The total number of trials or repetitions for each task, if applicable.\n",
        "\n",
        "Please avoid any explanation or not needed words In your answer.\n",
        "\"\"\"\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/Colab Notebooks/three-for-test-CHI.zip'\n",
        "unzip_dir = '/content/drive/MyDrive/Colab Notebooks/three-for-test-CHII/'\n",
        "output_df = pd.DataFrame(columns=['HTML Name', 'Output'])\n",
        "\n",
        "processed_files = load_processed_files_list()\n",
        "\n",
        "for filename in os.listdir(unzip_dir):\n",
        "    if filename not in processed_files:\n",
        "        file_path = os.path.join(unzip_dir, filename)\n",
        "\n",
        "        if filename.endswith('.html'):\n",
        "            text_content = html_to_text(file_path)\n",
        "        elif filename.endswith('.pdf'):\n",
        "            text_content = read_pdf(file_path)\n",
        "        elif filename.endswith('.zip'):\n",
        "            with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
        "                for zipped_name in zip_ref.namelist():\n",
        "                    with zip_ref.open(zipped_name) as file:\n",
        "                        soup = BeautifulSoup(file, 'html.parser')\n",
        "                        text_content = soup.get_text()\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        experiment_section = extract_experiment_section(text_content)\n",
        "\n",
        "        if experiment_section is not None:\n",
        "            combined_prompt = prompt + \"\\n\\n\" + \"Extracted Text:\" + \"\\n\" + experiment_section\n",
        "            combined_prompt = combined_prompt[:4097]\n",
        "\n",
        "            while True:\n",
        "                try:\n",
        "                    response = openai.Completion.create(\n",
        "                        engine=\"text-davinci-003\",\n",
        "                        prompt=combined_prompt,\n",
        "                        max_tokens=500\n",
        "                    )\n",
        "                    break\n",
        "                except openai.error.RateLimitError:\n",
        "                    print(\"Rate limit reached for API key {}. Switching to next API key...\".format(api_keys[api_key_index]))\n",
        "                    api_key_index = (api_key_index + 1) % len(api_keys)\n",
        "                    openai.api_key = api_keys[api_key_index]\n",
        "                    time.sleep(60)\n",
        "\n",
        "            new_row = pd.DataFrame({'HTML Name': [filename], 'Output': [response.choices[0].text.strip()]})\n",
        "        else:\n",
        "            new_row = pd.DataFrame({'HTML Name': [filename], 'Output': [\"No Experiment section found in the text.\"]})\n",
        "\n",
        "        output_df = pd.concat([output_df, new_row], ignore_index=True)\n",
        "        processed_files.append(filename)\n",
        "        save_processed_files_list(processed_files)\n",
        "        processed_files_count += 1\n",
        "\n",
        "        if processed_files_count % output_save_interval == 0:\n",
        "            output_df.to_excel('/content/drive/MyDrive/Colab Notebooks/OutputTest.xlsx', index=False)\n",
        "\n",
        "output_df.to_excel('/content/drive/MyDrive/Colab Notebooks/OutputTest.xlsx', index=False)"
      ],
      "metadata": {
        "id": "Jf58Dixghhr_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c83dbdd-d915-48e0-9e8e-6d16bbf7f697"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Rate limit reached for API key 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. Switching to next API key...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aLxoCHQ-iIDV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}